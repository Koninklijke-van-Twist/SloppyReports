{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad82bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewrote labels_template.csv with 2 columns.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "p = Path(r\"C:/Users/sokade/Downloads/sloppy_ml/labels_template.csv\")\n",
    "lines = [ln.strip() for ln in p.read_text(encoding=\"utf-8-sig\").splitlines() if ln.strip()]\n",
    "out = [\"report_id,label_codes\"]\n",
    "for s in lines[1:]:\n",
    "    \n",
    "    if s.startswith('\"') and s.endswith('\"'):\n",
    "        s = s[1:-1]\n",
    "    out.append(s)\n",
    "p.write_text(\"\\n\".join(out) + \"\\n\", encoding=\"utf-8\")\n",
    "print(\"Rewrote labels_template.csv with 2 columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdb74412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNS: ['report_id', 'label_codes']\n",
      " report_id                             label_codes\n",
      "   4083505 ATTRIBUTES_PARTIAL;MATERIALS_NOT_BOOKED\n",
      "   4083506 ATTRIBUTES_PARTIAL;MATERIALS_NOT_BOOKED\n",
      "   4083507 ATTRIBUTES_PARTIAL;MATERIALS_NOT_BOOKED\n",
      "   4083508 ATTRIBUTES_PARTIAL;MATERIALS_NOT_BOOKED\n",
      "   4083509 ATTRIBUTES_PARTIAL;MATERIALS_NOT_BOOKED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:/Users/sokade/Downloads/sloppy_ml/labels_template.csv\", encoding=\"utf-8-sig\")\n",
    "print(\"COLUMNS:\", list(df.columns))\n",
    "print(df.head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bca2e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re, json\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74845525",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Input and output directories\n",
    "BASE_DIR = Path(\"C:/Users/sokade/Downloads/sloppy_reports\")\n",
    "OUT_FINDINGS  = BASE_DIR / \"findings\"\n",
    "OUT_QUOTES    = BASE_DIR / \"quote_stub\"\n",
    "OUT_STRUCT    = BASE_DIR / \"structured\"\n",
    "\n",
    "# Create output folders if they don't exist\n",
    "for d in (OUT_FINDINGS, OUT_QUOTES, OUT_STRUCT):\n",
    "    d.mkdir(exist_ok=True)\n",
    "\n",
    "# --- PDF text extractor ---\n",
    "def extract_text_from_pdf(pdf_path: Path) -> str:\n",
    "    text = \"\"\n",
    "    try:\n",
    "        from PyPDF2 import PdfReader\n",
    "        text = \"\\n\".join([(p.extract_text() or \"\") for p in PdfReader(str(pdf_path)).pages])\n",
    "    except Exception:\n",
    "        pass\n",
    "    if not text.strip():\n",
    "        from pdfminer.high_level import extract_text\n",
    "        text = extract_text(str(pdf_path))\n",
    "    return text\n",
    "\n",
    "# --- Helpers\n",
    "def find(p, text, flags=re.I|re.S):\n",
    "    m = re.search(p, text, flags)\n",
    "    return m.group(1).strip() if m else None\n",
    "\n",
    "def has(p, text, flags=re.I|re.S): \n",
    "    return re.search(p, text, flags) is not None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dc3000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10038876_20250728_4083512_Microsoft AMS08 COLO2-CELLD SET_72H_SM04_1426.pdf ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# EDIT THIS BLOCK\n",
    "# --- Process each PDF ---\n",
    "for pdf in BASE_DIR.glob(\"*.pdf\"):\n",
    "    print(f\"Processing {pdf.name} ...\")\n",
    "    text = extract_text_from_pdf(pdf)\n",
    "\n",
    "    # --- Light extraction\n",
    "    report_id = find(r\"(?:Service\\s*report|Servicerapport)\\s*#?\\s*(\\d+)\", text)\n",
    "    arrival   = find(r\"(?:Time of Arrival|Arrival)[^\\d]*([0-2]?\\d:[0-5]\\d)\", text)\n",
    "    departure = find(r\"(?:Time of Departure|Departure)[^\\d]*([0-2]?\\d:[0-5]\\d)\", text)\n",
    "    total     = find(r\"(?:Total time spent working|Working hours)[^\\d]*([0-2]?\\d:[0-5]\\d)\", text)\n",
    "\n",
    "    attributes_block = find(r\"Attributes\\s*:?\\s*(.*?)(?:Executed maintenance|Comments|Signature|$)\", text)\n",
    "    attributes_filled = bool(attributes_block and re.search(r\"\\d|\\bV\\b|\\bA\\b|\\bL\\b|\\bbar\\b|\\b°C\\b\", attributes_block or \"\"))\n",
    "\n",
    "    comments = find(r\"(?:Comments|Notes)\\s*:?\\s*(.*?)(?:Signature|Executed maintenance|Situation on arrival|$)\", text) or \"\"\n",
    "\n",
    "    # Problem cues\n",
    "    fuel_polisher_leak = has(r\"fuel\\s+polisher\\s+pump.*leak\", text)\n",
    "    fuel_level_indicator_issue = has(r\"fuel\\s+level\\s+indicator.*(not|fault|replace)\", text)\n",
    "    repair_advice_present = has(r\"(repair|replacement)\\s+(advice|advies)\", text)\n",
    "    run_log_line = find(r\"(Record data on run log[^\\n]*)\", text)\n",
    "    run_log_incomplete = bool(run_log_line and re.search(r\"(not|n/?a|ordered|missing|later|resched)\", run_log_line, re.I))\n",
    "\n",
    "    # Findings\n",
    "    findings = []\n",
    "    if not total or total in (\"0:00\",\"00:00\"):\n",
    "        findings.append(dict(category=\"Admin\", issue=\"Working hours missing/zero\",\n",
    "                             action_request=\"Enter arrival, departure, and total working time.\"))\n",
    "\n",
    "    if not attributes_filled:\n",
    "        findings.append(dict(category=\"Attributes\", issue=\"Attributes not filled\",\n",
    "                             action_request=\"Fill power/battery/capacity/spec fields.\"))\n",
    "\n",
    "    if fuel_polisher_leak and not re.search(r\"(action|remedy|repaired|replaced|vervangen)\", comments, re.I):\n",
    "        findings.append(dict(category=\"Fuel System\", issue=\"Action missing for fuel polisher pump leak\",\n",
    "                             action_request=\"Add remedy (repair/replace), parts, and hours estimate.\"))\n",
    "\n",
    "    if fuel_level_indicator_issue:\n",
    "        findings.append(dict(category=\"Fuel System\", issue=\"Fuel level indicator decision missing\",\n",
    "                             action_request=\"Record customer decision (do not use / do not replace / replace).\"))\n",
    "\n",
    "    if run_log_incomplete:\n",
    "        findings.append(dict(category=\"Electrical/Logging\", issue=\"Run log not completed\",\n",
    "                             action_request=\"Attach metering run log or reschedule with tooling.\"))\n",
    "\n",
    "    # Quote stub\n",
    "    quote_stub = []\n",
    "    if fuel_polisher_leak or repair_advice_present:\n",
    "        quote_stub.append(dict(repair_advice=\"Fuel polisher pump repair/replacement\",\n",
    "                               material_code=\"\", specification=\"\", quantity=\"\", hours_estimate=\"\"))\n",
    "    if fuel_level_indicator_issue:\n",
    "        quote_stub.append(dict(repair_advice=\"Fuel l3evel indicator replacement\",\n",
    "                               material_code=\"\", specification=\"\", quantity=\"\", hours_estimate=\"\"))\n",
    "\n",
    "    # Save outputs\n",
    "    rid = report_id or pdf.stem.split(\"_\")[2]  # fallback: use the middle ID from filename\n",
    "    pd.DataFrame(findings).to_csv(OUT_FINDINGS / f\"findings_{rid}.csv\", index=False)\n",
    "    pd.DataFrame(quote_stub).to_csv(OUT_QUOTES / f\"quote_stub_{rid}.csv\", index=False)\n",
    "\n",
    "    structured = dict(\n",
    "        report_id=rid,\n",
    "        arrival=arrival, departure=departure, total_time_spent=total,\n",
    "        attributes_filled=attributes_filled,\n",
    "        flags=dict(\n",
    "            fuel_polisher_pump_leak=bool(fuel_polisher_leak),\n",
    "            fuel_level_indicator_issue=bool(fuel_level_indicator_issue),\n",
    "            repair_advice_present=bool(repair_advice_present),\n",
    "            run_log_incomplete=bool(run_log_incomplete),\n",
    "        ),\n",
    "        excerpts=dict(comments=comments[:400], attributes=(attributes_block or \"\")[:400])\n",
    "    )\n",
    "    with open(OUT_STRUCT / f\"structured_{rid}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(structured, f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ebccf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE → processed all PDFs in sloppy_reports/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"DONE → processed all PDFs in sloppy_reports/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3048e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
